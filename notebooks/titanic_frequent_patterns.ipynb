{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tra2rel(fileinput, fileoutput, delimiter=',', has_header=True):\n",
    "    data = open(fileinput, 'r')\n",
    "    if has_header:\n",
    "        data.readline()\n",
    "    baskets = defaultdict(list)\n",
    "\n",
    "    for row in data:\n",
    "        basket_id = row.replace('\\r\\n', '').split(delimiter)[0]\n",
    "        item_id = row.replace('\\r\\n', '').split(delimiter)[1]\n",
    "        baskets[basket_id].append(item_id)\n",
    "\n",
    "    data.close()\n",
    "\n",
    "    out = open(fileoutput, 'w')\n",
    "    for k, v in baskets.iteritems():\n",
    "        s = '%s' % k\n",
    "        for item in v:\n",
    "            s += ',%s' % item\n",
    "        out.write('%s\\n' % s)\n",
    "    out.close()\n",
    "    \n",
    "    return baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baskets = tra2rel('transactions.csv', 'baskets.csv', delimiter=',', has_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2663064031721',\n",
       " '2663064031720',\n",
       " '2663064031723',\n",
       " '2596064017113',\n",
       " '2596064017112',\n",
       " '2596064017111',\n",
       " '2596064017110',\n",
       " '2566064065708',\n",
       " '2566064065709',\n",
       " '2596064017115']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets.keys()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1108', '1140', '2017', '4180', '5030', '5064']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets['2663064031721']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fim\n",
    "from fim import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baskets_lists = [b for b in baskets.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1108', '1140', '2017', '4180', '5030', '5064'],\n",
       " ['1122', '2243', '2551', '3569', '3664', '3000442'],\n",
       " ['437', '559']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets_lists[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemsets = apriori(baskets_lists[:100], supp=2, zmin=2, target='a') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1658', '2650'), 2),\n",
       " (('3000442', '2551'), 2),\n",
       " (('2061', '3672'), 2),\n",
       " (('3086', '3087'), 2),\n",
       " (('5086', '2729', '445'), 2),\n",
       " (('5086', '2729'), 2),\n",
       " (('5086', '445'), 2),\n",
       " (('2674', '2650'), 2),\n",
       " (('608', '3087'), 2),\n",
       " (('2665', '2052'), 2),\n",
       " (('2665', '3828'), 2),\n",
       " (('2665', '3087'), 2),\n",
       " (('5072', '920'), 2),\n",
       " (('5025', '445'), 2),\n",
       " (('2058', '3448'), 2),\n",
       " (('2058', '445'), 2),\n",
       " (('3749', '3448'), 2),\n",
       " (('2080', '437'), 2),\n",
       " (('632', '2650'), 2),\n",
       " (('147', '1640'), 2),\n",
       " (('147', '2243'), 2),\n",
       " (('5069', '3750'), 2),\n",
       " (('441', '2193', '2504'), 2),\n",
       " (('441', '2193'), 2),\n",
       " (('441', '2504'), 2),\n",
       " (('2532', '4658'), 2),\n",
       " (('954', '3448'), 2),\n",
       " (('954', '4049'), 2),\n",
       " (('4029', '207'), 2),\n",
       " (('577', '2198'), 2),\n",
       " (('1257', '2009'), 2),\n",
       " (('4180', '2050'), 2),\n",
       " (('2494', '3448'), 2),\n",
       " (('1281', '2089'), 2),\n",
       " (('3690', '2727', '2729'), 2),\n",
       " (('3690', '2727'), 2),\n",
       " (('3690', '2729'), 2),\n",
       " (('4047', '2727', '2729'), 2),\n",
       " (('4047', '2727'), 2),\n",
       " (('4047', '2729'), 2),\n",
       " (('2495', '4776'), 2),\n",
       " (('617', '2242'), 2),\n",
       " (('617', '4600'), 2),\n",
       " (('617', '923'), 2),\n",
       " (('2551', '3828'), 2),\n",
       " (('4141', '1640'), 2),\n",
       " (('3447', '445'), 2),\n",
       " (('2050', '2762'), 2),\n",
       " (('5082', '437', '920', '2443'), 2),\n",
       " (('5082', '437', '920'), 2),\n",
       " (('5082', '437', '2443'), 2),\n",
       " (('5082', '437'), 2),\n",
       " (('5082', '920', '2443'), 2),\n",
       " (('5082', '920'), 2),\n",
       " (('5082', '2443'), 2),\n",
       " (('5085', '4655', '5087', '2443'), 2),\n",
       " (('5085', '4655', '5087'), 2),\n",
       " (('5085', '4655', '2443'), 2),\n",
       " (('5085', '4655'), 2),\n",
       " (('5085', '5087', '2443'), 2),\n",
       " (('5085', '5087'), 2),\n",
       " (('5085', '2443'), 2),\n",
       " (('4428', '2650'), 2),\n",
       " (('4428', '445'), 2),\n",
       " (('559', '445'), 2),\n",
       " (('2402', '2089'), 2),\n",
       " (('1090', '2089'), 2),\n",
       " (('2065', '4049'), 2),\n",
       " (('5064', '1579'), 2),\n",
       " (('2550', '4776', '2089'), 2),\n",
       " (('2550', '4776'), 2),\n",
       " (('2550', '2089'), 2),\n",
       " (('570', '2650'), 2),\n",
       " (('2528', '3074', '3672', '2443', '2762'), 2),\n",
       " (('2528', '3074', '3672', '2443'), 2),\n",
       " (('2528', '3074', '3672', '2762'), 2),\n",
       " (('2528', '3074', '3672'), 2),\n",
       " (('2528', '3074', '2443', '2762'), 2),\n",
       " (('2528', '3074', '2443'), 2),\n",
       " (('2528', '3074', '2762'), 2),\n",
       " (('2528', '3074'), 2),\n",
       " (('2528', '3672', '2443', '2762'), 2),\n",
       " (('2528', '3672', '2443'), 2),\n",
       " (('2528', '3672', '2762'), 2),\n",
       " (('2528', '3672'), 2),\n",
       " (('2528', '2443', '2762'), 2),\n",
       " (('2528', '2443'), 2),\n",
       " (('2528', '2762'), 2),\n",
       " (('4775', '1579'), 2),\n",
       " (('4775', '445'), 2),\n",
       " (('2097', '2085'), 2),\n",
       " (('2097', '4600', '437'), 2),\n",
       " (('2097', '4600'), 2),\n",
       " (('2097', '437'), 2),\n",
       " (('2097', '2089'), 2),\n",
       " (('2514', '3074', '923'), 2),\n",
       " (('2514', '3074'), 2),\n",
       " (('2514', '923'), 2),\n",
       " (('2514', '3672'), 2),\n",
       " (('4658', '3750', '445'), 2),\n",
       " (('4658', '3750'), 2),\n",
       " (('4658', '3074', '3087'), 2),\n",
       " (('4658', '3074'), 2),\n",
       " (('4658', '3087'), 2),\n",
       " (('4658', '445'), 2),\n",
       " (('487', '2074', '3449', '2504', '4049', '445'), 2),\n",
       " (('487', '2074', '3449', '2504', '4049'), 2),\n",
       " (('487', '2074', '3449', '2504', '445'), 2),\n",
       " (('487', '2074', '3449', '2504'), 2),\n",
       " (('487', '2074', '3449', '4049', '445'), 2),\n",
       " (('487', '2074', '3449', '4049'), 2),\n",
       " (('487', '2074', '3449', '445'), 2),\n",
       " (('487', '2074', '3449'), 2),\n",
       " (('487', '2074', '2504', '4049', '445'), 2),\n",
       " (('487', '2074', '2504', '4049'), 2),\n",
       " (('487', '2074', '2504', '445'), 2),\n",
       " (('487', '2074', '2504'), 2),\n",
       " (('487', '2074', '4049', '445'), 2),\n",
       " (('487', '2074', '4049'), 2),\n",
       " (('487', '2074', '445'), 2),\n",
       " (('487', '2074'), 2),\n",
       " (('487', '3449', '2504', '4049', '445'), 2),\n",
       " (('487', '3449', '2504', '4049'), 2),\n",
       " (('487', '3449', '2504', '445'), 2),\n",
       " (('487', '3449', '2504'), 2),\n",
       " (('487', '3449', '4049', '445'), 2),\n",
       " (('487', '3449', '4049'), 2),\n",
       " (('487', '3449', '445'), 2),\n",
       " (('487', '3449'), 2),\n",
       " (('487', '2504', '4049', '445'), 2),\n",
       " (('487', '2504', '4049'), 2),\n",
       " (('487', '2504', '445'), 2),\n",
       " (('487', '2504'), 2),\n",
       " (('487', '4049', '445'), 2),\n",
       " (('487', '4049'), 2),\n",
       " (('487', '445'), 2),\n",
       " (('476', '2193'), 2),\n",
       " (('2085', '2762'), 2),\n",
       " (('5074', '1687', '3449', '2504', '4776', '4049'), 2),\n",
       " (('5074', '1687', '3449', '2504', '4776'), 2),\n",
       " (('5074', '1687', '3449', '2504', '4049'), 2),\n",
       " (('5074', '1687', '3449', '2504'), 2),\n",
       " (('5074', '1687', '3449', '4776', '4049'), 2),\n",
       " (('5074', '1687', '3449', '4776'), 2),\n",
       " (('5074', '1687', '3449', '4049'), 2),\n",
       " (('5074', '1687', '3449'), 2),\n",
       " (('5074', '1687', '2504', '4776', '4049'), 2),\n",
       " (('5074', '1687', '2504', '4776'), 2),\n",
       " (('5074', '1687', '2504', '4049'), 2),\n",
       " (('5074', '1687', '2504'), 2),\n",
       " (('5074', '1687', '4776', '4049'), 2),\n",
       " (('5074', '1687', '4776'), 2),\n",
       " (('5074', '1687', '4049'), 2),\n",
       " (('5074', '1687'), 2),\n",
       " (('5074', '3449', '2504', '4776', '4049'), 2),\n",
       " (('5074', '3449', '2504', '4776'), 2),\n",
       " (('5074', '3449', '2504', '4049'), 2),\n",
       " (('5074', '3449', '2504'), 2),\n",
       " (('5074', '3449', '4776', '4049'), 2),\n",
       " (('5074', '3449', '4776'), 2),\n",
       " (('5074', '3449', '4049'), 2),\n",
       " (('5074', '3449'), 2),\n",
       " (('5074', '2504', '4776', '4049'), 2),\n",
       " (('5074', '2504', '4776'), 2),\n",
       " (('5074', '2504', '4049'), 2),\n",
       " (('5074', '2504'), 2),\n",
       " (('5074', '4776', '4049'), 2),\n",
       " (('5074', '4776'), 2),\n",
       " (('5074', '4049'), 2),\n",
       " (('1687', '3449', '2504', '4776', '4049'), 2),\n",
       " (('1687', '3449', '2504', '4776'), 2),\n",
       " (('1687', '3449', '2504', '4049'), 2),\n",
       " (('1687', '3449', '2504'), 2),\n",
       " (('1687', '3449', '4776', '4049'), 2),\n",
       " (('1687', '3449', '4776'), 2),\n",
       " (('1687', '3449', '4049'), 2),\n",
       " (('1687', '3449'), 2),\n",
       " (('1687', '2504', '4776', '4049'), 2),\n",
       " (('1687', '2504', '4776'), 2),\n",
       " (('1687', '2504', '4049'), 2),\n",
       " (('1687', '2504'), 2),\n",
       " (('1687', '4776', '4049'), 2),\n",
       " (('1687', '4776'), 2),\n",
       " (('1687', '4049'), 2),\n",
       " (('4163', '4832'), 2),\n",
       " (('2057', '2504'), 2),\n",
       " (('4655', '5087', '2443'), 2),\n",
       " (('4655', '5087'), 2),\n",
       " (('4655', '3672'), 2),\n",
       " (('4655', '2443'), 2),\n",
       " (('2242', '923'), 3),\n",
       " (('2242', '2650'), 2),\n",
       " (('2074', '3449', '2504', '4049', '445'), 2),\n",
       " (('2074', '3449', '2504', '4049'), 2),\n",
       " (('2074', '3449', '2504', '445'), 2),\n",
       " (('2074', '3449', '2504'), 2),\n",
       " (('2074', '3449', '4049', '445'), 2),\n",
       " (('2074', '3449', '4049'), 2),\n",
       " (('2074', '3449', '445'), 2),\n",
       " (('2074', '3449'), 2),\n",
       " (('2074', '2504', '4049', '445'), 2),\n",
       " (('2074', '2504', '4049'), 2),\n",
       " (('2074', '2504', '445'), 2),\n",
       " (('2074', '2504'), 2),\n",
       " (('2074', '4049', '445'), 2),\n",
       " (('2074', '4049'), 2),\n",
       " (('2074', '445'), 2),\n",
       " (('560', '920'), 2),\n",
       " (('560', '2089'), 2),\n",
       " (('207', '4832', '2762'), 2),\n",
       " (('207', '4832'), 2),\n",
       " (('207', '2762'), 2),\n",
       " (('3663', '920'), 2),\n",
       " (('5087', '2443'), 2),\n",
       " (('5087', '445'), 2),\n",
       " (('2193', '2504'), 2),\n",
       " (('2193', '445'), 2),\n",
       " (('2052', '2729'), 3),\n",
       " (('2052', '2729', '445'), 2),\n",
       " (('2052', '2650'), 3),\n",
       " (('2052', '2650', '445'), 2),\n",
       " (('2052', '445'), 3),\n",
       " (('2727', '4044'), 2),\n",
       " (('2727', '2729'), 3),\n",
       " (('2727', '2729', '3087'), 2),\n",
       " (('2727', '3087'), 2),\n",
       " (('1640', '446', '2650'), 2),\n",
       " (('1640', '446'), 2),\n",
       " (('1640', '2650'), 3),\n",
       " (('3828', '3739'), 2),\n",
       " (('3828', '3087'), 3),\n",
       " (('3750', '446'), 2),\n",
       " (('3750', '3739', '445'), 2),\n",
       " (('3750', '3739'), 2),\n",
       " (('3750', '3087', '445'), 2),\n",
       " (('3750', '3087'), 2),\n",
       " (('3750', '2443'), 2),\n",
       " (('3750', '445'), 4),\n",
       " (('4600', '437'), 3),\n",
       " (('4600', '437', '2650'), 2),\n",
       " (('4600', '923'), 2),\n",
       " (('4600', '2443'), 2),\n",
       " (('4600', '2650'), 2),\n",
       " (('4600', '2089'), 2),\n",
       " (('2009', '2194', '3448', '920'), 2),\n",
       " (('2009', '2194', '3448'), 2),\n",
       " (('2009', '2194', '920'), 2),\n",
       " (('2009', '2194'), 2),\n",
       " (('2009', '3448', '920'), 2),\n",
       " (('2009', '3448'), 2),\n",
       " (('2009', '920'), 3),\n",
       " (('2009', '920', '2443'), 2),\n",
       " (('2009', '2443'), 2),\n",
       " (('2194', '3448'), 3),\n",
       " (('2194', '3448', '920'), 2),\n",
       " (('2194', '3448', '923'), 2),\n",
       " (('2194', '920'), 2),\n",
       " (('2194', '923'), 2),\n",
       " (('2243', '2729', '3087'), 2),\n",
       " (('2243', '2729'), 2),\n",
       " (('2243', '3448'), 2),\n",
       " (('2243', '3087'), 2),\n",
       " (('1579', '4776'), 2),\n",
       " (('1579', '445'), 2),\n",
       " (('4832', '2762'), 2),\n",
       " (('3449', '2504', '4049'), 3),\n",
       " (('3449', '2504'), 3),\n",
       " (('3449', '4049'), 3),\n",
       " (('3449', '4776', '2504', '4049'), 2),\n",
       " (('3449', '4776', '2504'), 2),\n",
       " (('3449', '4776', '4049'), 2),\n",
       " (('3449', '4776'), 2),\n",
       " (('3449', '445', '2504', '4049'), 2),\n",
       " (('3449', '445', '2504'), 2),\n",
       " (('3449', '445', '4049'), 2),\n",
       " (('3449', '445'), 2),\n",
       " (('4044', '2729', '3739'), 2),\n",
       " (('4044', '2729'), 2),\n",
       " (('4044', '3739'), 2),\n",
       " (('4044', '3087'), 2),\n",
       " (('4044', '2650'), 2),\n",
       " (('4044', '2089'), 2),\n",
       " (('446', '3087', '445'), 2),\n",
       " (('446', '3087'), 2),\n",
       " (('446', '2650'), 3),\n",
       " (('446', '2650', '445'), 2),\n",
       " (('446', '445'), 5),\n",
       " (('2729', '3739'), 2),\n",
       " (('2729', '3087'), 3),\n",
       " (('2729', '3087', '445'), 2),\n",
       " (('2729', '2443', '2089'), 2),\n",
       " (('2729', '2443'), 2),\n",
       " (('2729', '2650'), 2),\n",
       " (('2729', '2089'), 2),\n",
       " (('2729', '445'), 3),\n",
       " (('2504', '4776', '4049'), 2),\n",
       " (('2504', '4776'), 2),\n",
       " (('2504', '4049'), 3),\n",
       " (('2504', '4049', '445'), 2),\n",
       " (('2504', '445'), 2),\n",
       " (('4776', '4049'), 2),\n",
       " (('4776', '2650'), 2),\n",
       " (('4776', '2089'), 2),\n",
       " (('3448', '920'), 2),\n",
       " (('3448', '923'), 2),\n",
       " (('3448', '2650'), 2),\n",
       " (('3448', '445'), 2),\n",
       " (('437', '920', '2443'), 2),\n",
       " (('437', '920'), 2),\n",
       " (('437', '3739'), 2),\n",
       " (('437', '3672'), 2),\n",
       " (('437', '2443'), 2),\n",
       " (('437', '2650'), 2),\n",
       " (('3074', '923'), 2),\n",
       " (('3074', '3672', '2443', '2762'), 2),\n",
       " (('3074', '3672', '2443'), 2),\n",
       " (('3074', '3672', '2762'), 2),\n",
       " (('3074', '3672'), 2),\n",
       " (('3074', '3087'), 2),\n",
       " (('3074', '2443', '2762'), 2),\n",
       " (('3074', '2443'), 2),\n",
       " (('3074', '2762'), 2),\n",
       " (('3074', '445'), 2),\n",
       " (('4049', '2089'), 2),\n",
       " (('4049', '445'), 2),\n",
       " (('920', '923', '3672'), 2),\n",
       " (('920', '923'), 2),\n",
       " (('920', '3672'), 2),\n",
       " (('920', '2443'), 3),\n",
       " (('3739', '3087'), 2),\n",
       " (('3739', '2443', '2089'), 2),\n",
       " (('3739', '2443'), 2),\n",
       " (('3739', '2762'), 3),\n",
       " (('3739', '2762', '445'), 2),\n",
       " (('3739', '2089'), 2),\n",
       " (('3739', '445'), 3),\n",
       " (('923', '3672'), 2),\n",
       " (('923', '2443'), 2),\n",
       " (('923', '445'), 2),\n",
       " (('3672', '2443', '2762'), 2),\n",
       " (('3672', '2443'), 2),\n",
       " (('3672', '2762'), 2),\n",
       " (('3672', '2650'), 2),\n",
       " (('3087', '2650'), 4),\n",
       " (('3087', '2650', '445'), 2),\n",
       " (('3087', '2089'), 2),\n",
       " (('3087', '445'), 4),\n",
       " (('2443', '2762'), 2),\n",
       " (('2443', '2089'), 4),\n",
       " (('2443', '2089', '445'), 3),\n",
       " (('2443', '445'), 3),\n",
       " (('2762', '445'), 3),\n",
       " (('2650', '2089'), 2),\n",
       " (('2650', '445'), 4),\n",
       " (('2089', '445'), 5)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rules = apriori(baskets_lists[:100], supp=3, zmin=2, target='r', \n",
    "                conf=90, report='ascl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4049', ('3449', '2504'), 3, 0.03, 1.0, 20.0),\n",
       " ('2504', ('3449', '4049'), 3, 0.03, 1.0, 25.0),\n",
       " ('3449', ('2504', '4049'), 3, 0.03, 1.0, 33.333333333333336),\n",
       " ('2504', ('3449',), 3, 0.03, 1.0, 25.0),\n",
       " ('4049', ('3449',), 3, 0.03, 1.0, 20.0),\n",
       " ('2089', ('2443', '445'), 3, 0.03, 1.0, 8.333333333333334)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function apriori in module fim:\n",
      "\n",
      "apriori(...)\n",
      "    apriori (tracts, target='s', supp=10, zmin=1, zmax=None, report='a',\n",
      "             eval='x', agg='x', thresh=10, prune=None, algo='b', mode='',\n",
      "             border=None)\n",
      "    Find frequent item sets with the Apriori algorithm.\n",
      "    tracts  transaction database to mine (mandatory)\n",
      "            The database must be an iterable of transactions;\n",
      "            each transaction must be an iterable of items;\n",
      "            each item must be a hashable object.\n",
      "            If the database is a dictionary, the transactions are\n",
      "            the keys, the values their (integer) multiplicities.\n",
      "    target  type of frequent item sets to find     (default: s)\n",
      "            s/a   sets/all   all     frequent item sets\n",
      "            c     closed     closed  frequent item sets\n",
      "            m     maximal    maximal frequent item sets\n",
      "            g     gens       generators\n",
      "            r     rules      association rules\n",
      "    supp    minimum support of an item set         (default: 10)\n",
      "            (positive: percentage, negative: absolute number)\n",
      "    conf    minimum confidence of an assoc. rule   (default: 80%)\n",
      "    zmin    minimum number of items per item set   (default: 1)\n",
      "    zmax    maximum number of items per item set   (default: no limit)\n",
      "    report  values to report with an item set      (default: a)\n",
      "            a     absolute item set support (number of transactions)\n",
      "            s     relative item set support as a fraction\n",
      "            S     relative item set support as a percentage\n",
      "            e     value of item set evaluation measure\n",
      "            E     value of item set evaluation measure as a percentage\n",
      "            (     combine values in a tuple (must be first character)\n",
      "            [     combine values in a list  (must be first character)\n",
      "            #     pattern spectrum as a dictionary  (no patterns)\n",
      "            =     pattern spectrum as a list        (no patterns)\n",
      "            |     pattern spectrum as three columns (no patterns)\n",
      "            for target 'r' (association rules) also available:\n",
      "            b     absolute body set  support (number of transactions)\n",
      "            x     relative body set  support as a fraction\n",
      "            X     relative body set  support as a percentage\n",
      "            h     absolute head item support (number of transactions)\n",
      "            y     relative head item support as a fraction\n",
      "            Y     relative head item support as a percentage\n",
      "            c     rule confidence as a fraction\n",
      "            C     rule confidence as a percentage\n",
      "            l     lift value of a rule (confidence/prior)\n",
      "            L     lift value of a rule as a percentage\n",
      "            Q     support of the empty set (total number of transactions)\n",
      "    eval    measure for item set evaluation        (default: x)\n",
      "            x     none       no measure / zero (default)\n",
      "            b     ldratio    binary logarithm of support quotient       (+)\n",
      "            c     conf       rule confidence                            (+)\n",
      "            d     confdiff   absolute confidence difference to prior    (+)\n",
      "            l     lift       lift value (confidence divided by prior)   (+)\n",
      "            a     liftdiff   absolute difference of lift value to 1     (+)\n",
      "            q     liftquot   difference of lift quotient to 1           (+)\n",
      "            v     cvct       conviction (inverse lift for negated head) (+)\n",
      "            e     cvctdiff   absolute difference of conviction to 1     (+)\n",
      "            r     cvctquot   difference of conviction quotient to 1     (+)\n",
      "            k     cprob      conditional probability ratio              (+)\n",
      "            j     import     importance (binary log. of prob. ratio)    (+)\n",
      "            z     cert       certainty factor (relative conf. change)   (+)\n",
      "            n     chi2       normalized chi^2 measure                   (+)\n",
      "            p     chi2pval   p-value from (unnormalized) chi^2 measure  (-)\n",
      "            y     yates      normalized chi^2 with Yates' correction    (+)\n",
      "            t     yatespval  p-value from Yates-corrected chi^2 measure (-)\n",
      "            i     info       information difference to prior            (+)\n",
      "            g     infopval   p-value from G statistic/info. difference  (-)\n",
      "            f     fetprob    Fisher's exact test (table probability)    (-)\n",
      "            h     fetchi2    Fisher's exact test (chi^2 measure)        (-)\n",
      "            m     fetinfo    Fisher's exact test (mutual information)   (-)\n",
      "            s     fetsupp    Fisher's exact test (support)              (-)\n",
      "            Measures marked with (+) must meet or exceed the threshold,\n",
      "            measures marked with (-) must not exceed the threshold\n",
      "            in order for the item set to be reported.\n",
      "    agg     evaluation measure aggregation mode    (default: x)\n",
      "            x     none       no aggregation (use first value)\n",
      "            m     min        minimum of individual measure values\n",
      "            n     max        maximum of individual measure values\n",
      "            a     avg        average of individual measure values\n",
      "    thresh  threshold for evaluation measure       (default: 10%)\n",
      "    prune   min. size for evaluation filtering     (default: no pruning)\n",
      "            = 0   backward filtering       (no subset check)\n",
      "            < 0   weak   forward filtering (one subset  must qualify)\n",
      "            > 0   strong forward filtering (all subsets must qualify)\n",
      "    algo    algorithm variant to use               (default: a)\n",
      "            b     basic      standard algorithm (only choice)\n",
      "    mode    operation mode indicators/flags        (default: None)\n",
      "            x     do not use perfect extension pruning\n",
      "            t/T   do not organize transactions as a prefix tree\n",
      "            y     a-posteriori pruning of infrequent item sets\n",
      "            z     invalidate evaluation below expected support\n",
      "            o     use original rule support definition (body & head)\n",
      "    border  support border for filtering item sets (default: None)\n",
      "            Must be a list or tuple of (absolute) minimum support values\n",
      "            per item set size (by which the list/tuple is indexed).\n",
      "    appear  dictionary mapping items to item appearance indicators,\n",
      "            with the key None referring to the default item appearance.\n",
      "            (If None does not occur as a key or no dictionary is given,\n",
      "            the default item appearance indicator is 'both'.)\n",
      "            This parameter is only used if the target type is rules.\n",
      "            * item may not appear anywhere in a rule:\n",
      "              '-', 'n', 'none', 'neither', 'ignore'\n",
      "            * item may appear only in rule body/antecedent:\n",
      "              'i', 'in', 'inp', 'input', 'b', 'body',\n",
      "              'a', 'ante', 'antecedent'\n",
      "            * item may appear only in rule head/consequent:\n",
      "              'o', 'out',      'output', 'h', 'head',\n",
      "              'c', 'cons', 'consequent'\n",
      "            * item may appear anywhere in a rule:\n",
      "              'io', 'i&o', 'inout', 'in&out', 'bh', 'b&h', 'both'\n",
      "    returns if report is not in ['#','=','|']:\n",
      "              if the target is association rules:\n",
      "                a list of rules (i.e. tuples with two or more elements),\n",
      "                each consisting of a head/consequent item, a tuple with\n",
      "                a body/antecedent item set, and the values selected by\n",
      "                the parameter 'report', which may be combined into a\n",
      "                tuple or a list if report[0] is '(' or '[', respectively.          if the target is a type of item sets:\n",
      "                a list of patterns (i.e. tuples with one or more elements),\n",
      "                each consisting of a tuple with a found frequent item set\n",
      "                and the values selected by the parameter 'report', which\n",
      "                may be combined into a tuple or list if report[0] is '('\n",
      "                or '[', respectively\n",
      "            if report in ['#','=','|']:\n",
      "              a pattern spectrum as a dictionary mapping pattern sizes\n",
      "              to the corresponding occurrence support ranges, as a list\n",
      "              of triplets (size, min. support, max. support) or as three\n",
      "              columns for sizes and minimum and maximum support values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fim.apriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calling external C function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_apriori(fileinput, fileoutput, delimiter=',', target_type='s', \n",
    "                 min_nbr_items=1, min_sup=2, min_conf=2):\n",
    "    # apriori\n",
    "    # -t# {m: maximal, c: closed, s: frequent, r: association rules}\n",
    "    # -m# minimum number of items per item set/association rule\n",
    "    # -s# minimum support of an item set, positive: percentage, negative: absolute\n",
    "    # -c# minimum confidence rule percentage\n",
    "    # -b# line delimiter (,)\n",
    "    # The default additional information output format for rules is \" (%X, %C)\"\n",
    "    # %X relative body set support as a percentage\n",
    "    # %C rule confidence as a percentage\n",
    "    # %L lift\n",
    "\n",
    "    if target_type == 'r':\n",
    "        call_cmd = ['./apriori', '-b%s' % delimiter, '-t%s' % target_type, '-m%s' % min_nbr_items, \n",
    "                    '-s%s' % min_sup, '-c%s' % min_conf, '-v (%X, %C, %L)', \n",
    "                    fileinput, fileoutput]\n",
    "    else:\n",
    "        call_cmd = ['./apriori', '-b%s' % delimiter, '-t%s' % target_type, \n",
    "                           '-m%s' % min_nbr_items, '-s%s' % min_sup, fileinput, fileoutput]\n",
    "\n",
    "    ret = subprocess.call(call_cmd,  stdout=open('apriori_stdout.txt', 'w'), \n",
    "                          stderr=open('apriori_stderr.txt', 'w'))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delimiter=','\n",
    "target_type='s'\n",
    "min_nbr_items=3\n",
    "min_sup=1\n",
    "\n",
    "ret_val = call_apriori('baskets.csv', 'freq_patterns.txt', \n",
    "                       delimiter, target_type, \n",
    "                       min_nbr_items, min_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delimiter=','\n",
    "target_type='r'\n",
    "min_nbr_items=3\n",
    "min_sup=2\n",
    "min_conf=25\n",
    "\n",
    "ret_val = call_apriori('baskets.csv', 'rules.txt', delimiter, target_type, \n",
    "                       min_nbr_items, min_sup, min_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_rules(filename):\n",
    "    data = open(filename, 'r')\n",
    "    rules = list()\n",
    "    for row in data:\n",
    "        fileds = row.rstrip('\\n\\r').split(' <- ')\n",
    "        cons = fileds[0]\n",
    "        other = fileds[1].split(' (')\n",
    "        ant = other[0].split(' ')\n",
    "        other2 = other[1].split(', ')\n",
    "        sup = float(other2[0])\n",
    "        conf = float(other2[1])\n",
    "        lift = float(other2[2].replace(')', ''))\n",
    "        rule = {\n",
    "            'ant': ant,\n",
    "            'cons': cons,\n",
    "            'sup': sup,\n",
    "            'conf': conf,\n",
    "            'lift': lift\n",
    "        }\n",
    "        rules.append(rule)\n",
    "    data.close()\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2729', '2650'] --> 2727  lift 495.026  conf 26.9805\n",
      "['3448', '2443'] --> 2193  lift 312.362  conf 26.0954\n",
      "['2193', '2443'] --> 3448  lift 343.622  conf 25.9445\n"
     ]
    }
   ],
   "source": [
    "rules = read_rules('rules.txt')\n",
    "for r in rules[:3]:\n",
    "    print r['ant'], '-->', r['cons'], ' lift', r['lift'], ' conf', r['conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ant': ['2729', '2650'],\n",
       " 'conf': 26.9805,\n",
       " 'cons': '2727',\n",
       " 'lift': 495.026,\n",
       " 'sup': 2.13263}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frequent Pattern Mining on Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(df, drop_passenger_id):\n",
    "    \n",
    "    # Get the unique values of Sex\n",
    "    sexes = sorted(df['Sex'].unique())\n",
    "    \n",
    "    # Generate a mapping of Sex from a string to a number representation    \n",
    "    genders_mapping = dict(zip(sexes, range(0, len(sexes) + 1)))\n",
    "    \n",
    "    #print genders_mapping\n",
    "\n",
    "    # Transform Sex from a string to a number representation\n",
    "    df['Sex_Val'] = df['Sex'].map(genders_mapping).astype(int)\n",
    "    \n",
    "    # Get the unique values of Embarked\n",
    "    #embarked_locs = sorted(df['Embarked'].unique())\n",
    "\n",
    "    # Generate a mapping of Embarked from a string to a number representation        \n",
    "    #embarked_locs_mapping = dict(zip(embarked_locs, \n",
    "                                     #range(0, len(embarked_locs) + 1)))\n",
    "    \n",
    "    \n",
    "    embarked_locs = sorted(df['Embarked'].unique())\n",
    "    embarked_locs_mapping = dict(zip(embarked_locs, range(0, len(embarked_locs) + 1)))\n",
    "    \n",
    "    #print embarked_locs_mapping\n",
    "    \n",
    "    \n",
    "    df['Embarked_Val'] = df['Embarked'].map(embarked_locs_mapping).astype(int)\n",
    "    if len(df[df['Embarked'].isnull()] > 0):\n",
    "        df.replace({'Embarked_Val' : { embarked_locs_mapping[np.nan] : embarked_locs_mapping['S']}}, \n",
    "               inplace=True)\n",
    "    \n",
    "    ## Transform Embarked from a string to dummy variables\n",
    "    #df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked_Val')], axis=1)\n",
    "    \n",
    "    ## Fill in missing values of Embarked\n",
    "    ## Since the vast majority of passengers embarked in 'S': 3, \n",
    "    ## we assign the missing values in Embarked to 'S':\n",
    "    #if len(df[df['Embarked'].isnull()] > 0):\n",
    "    #    df.replace({'Embarked_Val' : \n",
    "    #                   { embarked_locs_mapping[np.nan] : embarked_locs_mapping['S'] \n",
    "    #                   }\n",
    "    #               }, \n",
    "    #               inplace=True)\n",
    "    \n",
    "    # Fill in missing values of Fare with the average Fare\n",
    "    if len(df[df['Fare'].isnull()] > 0):\n",
    "        avg_fare = df['Fare'].mean()\n",
    "        df.replace({ None: avg_fare }, inplace=True)\n",
    "    \n",
    "    # To keep Age in tact, make a copy of it called AgeFill \n",
    "    # that we will use to fill in the missing ages:\n",
    "    df['AgeFill'] = df['Age']\n",
    "\n",
    "    # Determine the Age typical for each passenger class by Sex_Val.  \n",
    "    # We'll use the median instead of the mean because the Age \n",
    "    # histogram seems to be right skewed.\n",
    "    df['AgeFill'] = df['AgeFill'] \\\n",
    "                        .groupby([df['Sex_Val'], df['Pclass']]) \\\n",
    "                        .apply(lambda x: x.fillna(x.median()))\n",
    "            \n",
    "    # Define a new feature FamilySize that is the sum of \n",
    "    # Parch (number of parents or children on board) and \n",
    "    # SibSp (number of siblings or spouses):\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "    \n",
    "    # Drop the columns we won't use:\n",
    "    df = df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "    \n",
    "    # Drop the Age column since we will be using the AgeFill column instead.\n",
    "    # Drop the SibSp and Parch columns since we will be using FamilySize.\n",
    "    # Drop the PassengerId column since it won't be used as a feature.\n",
    "    df = df.drop(['Age', 'SibSp', 'Parch'], axis=1)\n",
    "    \n",
    "    if drop_passenger_id:\n",
    "        df = df.drop(['PassengerId'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = clean_data(df, drop_passenger_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_Val</th>\n",
       "      <th>Embarked_Val</th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Fare  Sex_Val  Embarked_Val  AgeFill  \\\n",
       "0            1         0       3   7.2500        1             3     22.0   \n",
       "1            2         1       1  71.2833        0             1     38.0   \n",
       "2            3         1       3   7.9250        0             3     26.0   \n",
       "3            4         1       1  53.1000        0             3     35.0   \n",
       "4            5         0       3   8.0500        1             3     35.0   \n",
       "\n",
       "   FamilySize  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['AgeGroup'] = pd.cut(df2['AgeFill'], bins=range(0, 105, 10), \n",
    "                         right=False, labels=range(0, 100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_Val</th>\n",
       "      <th>Embarked_Val</th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>AgeGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Fare  Sex_Val  Embarked_Val  AgeFill  \\\n",
       "0            1         0       3   7.2500        1             3     22.0   \n",
       "1            2         1       1  71.2833        0             1     38.0   \n",
       "2            3         1       3   7.9250        0             3     26.0   \n",
       "3            4         1       1  53.1000        0             3     35.0   \n",
       "4            5         0       3   8.0500        1             3     35.0   \n",
       "\n",
       "   FamilySize AgeGroup  \n",
       "0           1       20  \n",
       "1           1       30  \n",
       "2           0       20  \n",
       "3           1       30  \n",
       "4           0       30  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['FareGroup'] = pd.cut(df2['Fare'], bins=range(0, 520, 10), \n",
    "                          right=False, labels=range(0, 510, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_Val</th>\n",
       "      <th>Embarked_Val</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex_Val  Embarked_Val  FamilySize AgeGroup  \\\n",
       "0            1         0       3        1             3           1       20   \n",
       "1            2         1       1        0             1           1       30   \n",
       "2            3         1       3        0             3           0       20   \n",
       "3            4         1       1        0             3           1       30   \n",
       "4            5         0       3        1             3           0       30   \n",
       "\n",
       "  FareGroup  \n",
       "0         0  \n",
       "1        70  \n",
       "2         0  \n",
       "3        50  \n",
       "4         0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.drop(['AgeFill', 'Fare'], axis=1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df2\n",
    "df3['Survived'] = df2['Survived'].astype(str) + '_S'\n",
    "df3['Pclass'] = df2['Pclass'].astype(str) + '_P'\n",
    "df3['Sex_Val'] = df2['Sex_Val'].map({1: 'M', 0: 'F'}).astype(str)\n",
    "df3['Embarked_Val'] = df2['Embarked_Val'].map({2:'Q', 1:'C', 3:'S'}).astype(str)\n",
    "df3['FamilySize'] = df2['FamilySize'].astype(str) + '_FS'\n",
    "df3['AgeGroup'] = df2['AgeGroup'].astype(str) + '_A'\n",
    "df3['FareGroup'] = df2['FareGroup'].astype(str) + '_F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_Val</th>\n",
       "      <th>Embarked_Val</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0_S</td>\n",
       "      <td>3_P</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>1_FS</td>\n",
       "      <td>20_A</td>\n",
       "      <td>0.0_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1_S</td>\n",
       "      <td>1_P</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>1_FS</td>\n",
       "      <td>30_A</td>\n",
       "      <td>70.0_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1_S</td>\n",
       "      <td>3_P</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>0_FS</td>\n",
       "      <td>20_A</td>\n",
       "      <td>0.0_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1_S</td>\n",
       "      <td>1_P</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>1_FS</td>\n",
       "      <td>30_A</td>\n",
       "      <td>50.0_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0_S</td>\n",
       "      <td>3_P</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>0_FS</td>\n",
       "      <td>30_A</td>\n",
       "      <td>0.0_F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId Survived Pclass Sex_Val Embarked_Val FamilySize AgeGroup  \\\n",
       "0            1      0_S    3_P       M            S       1_FS     20_A   \n",
       "1            2      1_S    1_P       F            C       1_FS     30_A   \n",
       "2            3      1_S    3_P       F            S       0_FS     20_A   \n",
       "3            4      1_S    1_P       F            S       1_FS     30_A   \n",
       "4            5      0_S    3_P       M            S       0_FS     30_A   \n",
       "\n",
       "  FareGroup  \n",
       "0     0.0_F  \n",
       "1    70.0_F  \n",
       "2     0.0_F  \n",
       "3    50.0_F  \n",
       "4     0.0_F  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.to_csv('titanic_for_patterns.csv', sep=',', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delimiter=','\n",
    "target_type='s'\n",
    "min_nbr_items=2\n",
    "min_sup=2\n",
    "min_conf=2\n",
    "\n",
    "ret_val = call_apriori('titanic_for_patterns.csv', 'titanic_freq_patterns.txt', \n",
    "                       delimiter, target_type, min_nbr_items, min_sup, min_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delimiter=','\n",
    "target_type='r'\n",
    "min_nbr_items=2\n",
    "min_sup=2\n",
    "min_conf=25\n",
    "\n",
    "ret_val = call_apriori('titanic_for_patterns.csv', 'titanic_rules.txt', delimiter, target_type, \n",
    "                       min_nbr_items, min_sup, min_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_A', '3_P', '0_S', 'S'] --> 6_FS  lift 2062.5  conf 27.7778\n",
      "['0_A', '0_S', 'S'] --> 6_FS  lift 1953.95  conf 26.3158\n",
      "['30.0_F', 'F', 'S'] --> 6_FS  lift 2735.53  conf 36.8421\n"
     ]
    }
   ],
   "source": [
    "rules = read_rules('titanic_rules.txt')\n",
    "for r in rules[:3]:\n",
    "    print r['ant'], '-->', r['cons'], ' lift', r['lift'], ' conf', r['conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rulse_cons_S = list()\n",
    "for r in rules:\n",
    "    if r['cons'].endswith('_S'):\n",
    "        rulse_cons_S.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892\n"
     ]
    }
   ],
   "source": [
    "print len(rulse_cons_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_rules_cons_S = sorted(rulse_cons_S, \n",
    "                             key=lambda r: r['conf'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_A', '2_FS', 'S'] --> 1_S  lift 260.526  conf 100.0\n",
      "['1_FS', 'C', '1_P', 'F'] --> 1_S  lift 260.526  conf 100.0\n",
      "['1_FS', '1_P', 'F', 'S'] --> 1_S  lift 260.526  conf 100.0\n",
      "['1_FS', '1_P', 'F'] --> 1_S  lift 260.526  conf 100.0\n",
      "['10.0_F', '2_P', '20_A', 'M', 'S'] --> 0_S  lift 162.295  conf 100.0\n",
      "['10.0_F', '2_P', '20_A', 'M'] --> 0_S  lift 162.295  conf 100.0\n",
      "['10.0_F', '20_A', '0_FS', 'M', 'S'] --> 0_S  lift 162.295  conf 100.0\n",
      "['10.0_F', '20_A', 'M', 'S'] --> 0_S  lift 162.295  conf 100.0\n",
      "['2_P', '20_A', '0_FS', 'M', 'S'] --> 0_S  lift 162.295  conf 100.0\n",
      "['2_P', '20_A', '0_FS', 'M'] --> 0_S  lift 162.295  conf 100.0\n"
     ]
    }
   ],
   "source": [
    "for r in sorted_rules_cons_S[:10]:\n",
    "    print r['ant'], '-->', r['cons'], ' lift', r['lift'], ' conf', r['conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, '0_S', '3_P', 'M', 'S', '1_FS', '20_A', '0.0_F'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "passenger_test = df3.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_FS', '20_A', '3_P', 'S'] --> 1_S\n",
      "['1_FS', '20_A', '3_P'] --> 1_S\n",
      "['1_FS', '20_A', 'S'] --> 1_S\n",
      "['1_FS', '20_A'] --> 1_S\n",
      "['1_FS', '3_P', 'S'] --> 1_S\n",
      "['1_FS', '3_P'] --> 1_S\n",
      "['1_FS', 'S'] --> 1_S\n",
      "['1_FS'] --> 1_S\n",
      "['1_FS', '20_A', '3_P', 'M'] --> 0_S\n",
      "['1_FS', '20_A', '3_P', 'S'] --> 0_S\n",
      "['1_FS', '20_A', '3_P'] --> 0_S\n",
      "['1_FS', '20_A', 'M', 'S'] --> 0_S\n",
      "['1_FS', '20_A', 'M'] --> 0_S\n",
      "['1_FS', '20_A', 'S'] --> 0_S\n",
      "['1_FS', '20_A'] --> 0_S\n",
      "['1_FS', '3_P', 'M', 'S'] --> 0_S\n",
      "['1_FS', '3_P', 'M'] --> 0_S\n",
      "['1_FS', '3_P', 'S'] --> 0_S\n",
      "['1_FS', '3_P'] --> 0_S\n",
      "['1_FS', 'M', 'S'] --> 0_S\n",
      "['1_FS', 'M'] --> 0_S\n",
      "['1_FS', 'S'] --> 0_S\n",
      "['1_FS'] --> 0_S\n",
      "['0.0_F', '20_A', '3_P', 'M', 'S'] --> 0_S\n",
      "['0.0_F', '20_A', '3_P', 'M'] --> 0_S\n",
      "['0.0_F', '20_A', '3_P', 'S'] --> 0_S\n",
      "['0.0_F', '20_A', '3_P'] --> 0_S\n",
      "['0.0_F', '20_A', 'M', 'S'] --> 0_S\n",
      "['0.0_F', '20_A', 'M'] --> 0_S\n",
      "['0.0_F', '20_A', 'S'] --> 0_S\n",
      "['0.0_F', '20_A'] --> 0_S\n",
      "['0.0_F', '3_P', 'M', 'S'] --> 0_S\n",
      "['0.0_F', '3_P', 'M'] --> 0_S\n",
      "['0.0_F', '3_P', 'S'] --> 0_S\n",
      "['0.0_F', '3_P'] --> 0_S\n",
      "['0.0_F', 'M', 'S'] --> 0_S\n",
      "['0.0_F', 'M'] --> 0_S\n",
      "['0.0_F', 'S'] --> 0_S\n",
      "['0.0_F'] --> 0_S\n",
      "['20_A'] --> 1_S\n",
      "['S'] --> 1_S\n",
      "['20_A', '3_P', 'M', 'S'] --> 0_S\n",
      "['20_A', '3_P', 'M'] --> 0_S\n",
      "['20_A', '3_P', 'S'] --> 0_S\n",
      "['20_A', '3_P'] --> 0_S\n",
      "['20_A', 'M', 'S'] --> 0_S\n",
      "['20_A', 'M'] --> 0_S\n",
      "['20_A', 'S'] --> 0_S\n",
      "['20_A'] --> 0_S\n",
      "['3_P', 'M', 'S'] --> 0_S\n",
      "['3_P', 'M'] --> 0_S\n",
      "['3_P', 'S'] --> 0_S\n",
      "['3_P'] --> 0_S\n",
      "['M', 'S'] --> 0_S\n",
      "['M'] --> 0_S\n",
      "['S'] --> 0_S\n"
     ]
    }
   ],
   "source": [
    "for r in rules:\n",
    "    if set(r['ant']) < set(passenger_test) and r['cons'].endswith('_S'):\n",
    "        print r['ant'], '-->', r['cons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_baskets_list = list()\n",
    "for row in df3.values:\n",
    "    titanic_baskets_list.append(list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rules = apriori(titanic_baskets_list, supp=5, zmin=2, target='r', conf=90, report='ascl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1_S', ('2_P', 'F', 'S'), 61, 0.06846240179573512, 0.9104477611940298, 2.3719560094265515)\n",
      "('1_S', ('2_P', 'F'), 70, 0.07856341189674523, 0.9210526315789473, 2.399584487534626)\n",
      "('1_S', ('1_P', 'F', 'S'), 48, 0.05387205387205387, 0.96, 2.5010526315789474)\n",
      "('1_S', ('1_P', 'F'), 91, 0.10213243546576879, 0.9680851063829787, 2.5221164613661813)\n"
     ]
    }
   ],
   "source": [
    "for rule in rules:\n",
    "    if rule[0] == '1_S':\n",
    "        print rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
